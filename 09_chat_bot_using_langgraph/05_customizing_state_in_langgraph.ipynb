{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can add additional fields to the state\n",
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    name: str\n",
    "    birthday: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will populate the state keys inside of our \n",
    "# human_assistance tool\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "@tool\n",
    "# Note that because we are generating a ToolMessage for a state update, we\n",
    "# generally require the ID of the corresponding tool call. We can use\n",
    "# LangChain's InjectedToolCallId to signal that this argument should not\n",
    "# be revealed to the model in the tool's schema.\n",
    "def human_assistance(name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]) -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    human_response = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            \"name\": name,\n",
    "            \"birthday\": birthday\n",
    "        }\n",
    "    )\n",
    "    # If the information is correct, update the state as-is.\n",
    "    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\n",
    "        verified_name = name\n",
    "        verified_birthday = birthday\n",
    "        response = \"Correct\"\n",
    "    # Otherwise, receive information from the human reviewer.\n",
    "    else:\n",
    "        verified_name = human_response.get(\"name\", name)\n",
    "        verified_birthday = human_response.get(\"birthday\", birthday)\n",
    "        response = f\"Made a correction: {human_response}\"\n",
    "\n",
    "    # This time we explicitly update the state with a ToolMessage \n",
    "    # inside the tool.\n",
    "    state_update = {\n",
    "        \"name\": verified_name,\n",
    "        \"birthday\": verified_birthday,\n",
    "        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)]\n",
    "    }\n",
    "    # We return a Command object in the tool to update our state.\n",
    "    return Command(update=state_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the rest of our graph is the same\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool, human_assistance]\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    assert len(message.tool_calls) <= 1\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_EO7veL92xLNN8oENnAoL5RNj)\n",
      " Call ID: call_EO7veL92xLNN8oENnAoL5RNj\n",
      "  Args:\n",
      "    query: LangGraph release date\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://github.com/langchain-ai/langgraph/releases\", \"content\": \"Releases · langchain-ai/langgraph · GitHub Search code, repositories, users, issues, pull requests... Releases: langchain-ai/langgraph Releases · langchain-ai/langgraph langgraph: release 0.2.70 (#3341) langgraph: add agent name to AI messages in create_react_agent (#3340) fix(langgraph): Dedupe input (right-side) messages in add_messages (#3338) Merge branch 'jacob/dedupe' of github.com:langchain-ai/langgraph into jacob/dedupe langgraph: release 0.2.69 (#3256) docs: update README to include built w/ langgraph (#3254) langgraph: add get_stream_writer() (#3251) langgraph: release 0.2.68 (#3224) langgraph: actually fix flaky test (#3219) langgraph: use 'prompt' param for model input preprocessing in create_react_agent (#3173) langgraph: fix flaky test (#3218) langgraph: add names for tasks (#3202) langgraph: update docstrings/api ref for functional api (#3176) langgraph: add support for BaseModel updates to Command (#2747) langgraph: allow async state modifier in create_react_agent (#3161)\"}, {\"url\": \"https://pypi.org/project/langgraph/\", \"content\": \"LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. The simplest way to create a tool-calling agent in LangGraph is to use create_react_agent: # Define the tools for the agent to use # Define the tools for the agent to use # This means that after `tools` is called, `agent` node is called next. workflow.add_edge(\\\"tools\\\", 'agent') Normal edge: after the tools are invoked, the graph should always return to the agent to decide what to do next LangGraph adds the input message to the internal state, then passes the state to the entrypoint node, \\\"agent\\\". langgraph-0.2.70-py3-none-any.whl (149.7 kB view details)Uploaded Feb 6, 2025 Python 3\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  human_assistance (call_PErDtZj1ubVAMokPKxzl2hjy)\n",
      " Call ID: call_PErDtZj1ubVAMokPKxzl2hjy\n",
      "  Args:\n",
      "    name: LangGraph\n",
      "    birthday: February 6, 2025\n"
     ]
    }
   ],
   "source": [
    "# Let's prompt our application to look up the \"birthday\" of the LangGraph library.\n",
    "user_input = (\n",
    "    \"Can you look up when LangGraph was released? \"\n",
    "    \"When you have the answer, use the human_assistance tool for review.\"\n",
    ")\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  human_assistance (call_PErDtZj1ubVAMokPKxzl2hjy)\n",
      " Call ID: call_PErDtZj1ubVAMokPKxzl2hjy\n",
      "  Args:\n",
      "    name: LangGraph\n",
      "    birthday: February 6, 2025\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: human_assistance\n",
      "\n",
      "Made a correction: {'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph was released on January 17, 2024.\n"
     ]
    }
   ],
   "source": [
    "# We've hit the interrupt in the human_assistance tool again. \n",
    "# In this case, the chatbot failed to identify the correct date, \n",
    "# so we can supply it\n",
    "human_command = Command(\n",
    "    resume={\n",
    "        \"name\": \"LangGraph\",\n",
    "        \"birthday\": \"Jan 17, 2024\",\n",
    "    },\n",
    ")\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review.', additional_kwargs={}, response_metadata={}, id='ea88a224-d8e8-45fb-babd-576432426b50'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_EO7veL92xLNN8oENnAoL5RNj', 'function': {'arguments': '{\"query\":\"LangGraph release date\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 129, 'total_tokens': 151, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-9b05e470-6a6f-4942-b6e0-320fc3338d35-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph release date'}, 'id': 'call_EO7veL92xLNN8oENnAoL5RNj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 129, 'output_tokens': 22, 'total_tokens': 151, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='[{\"url\": \"https://github.com/langchain-ai/langgraph/releases\", \"content\": \"Releases · langchain-ai/langgraph · GitHub Search code, repositories, users, issues, pull requests... Releases: langchain-ai/langgraph Releases · langchain-ai/langgraph langgraph: release 0.2.70 (#3341) langgraph: add agent name to AI messages in create_react_agent (#3340) fix(langgraph): Dedupe input (right-side) messages in add_messages (#3338) Merge branch \\'jacob/dedupe\\' of github.com:langchain-ai/langgraph into jacob/dedupe langgraph: release 0.2.69 (#3256) docs: update README to include built w/ langgraph (#3254) langgraph: add get_stream_writer() (#3251) langgraph: release 0.2.68 (#3224) langgraph: actually fix flaky test (#3219) langgraph: use \\'prompt\\' param for model input preprocessing in create_react_agent (#3173) langgraph: fix flaky test (#3218) langgraph: add names for tasks (#3202) langgraph: update docstrings/api ref for functional api (#3176) langgraph: add support for BaseModel updates to Command (#2747) langgraph: allow async state modifier in create_react_agent (#3161)\"}, {\"url\": \"https://pypi.org/project/langgraph/\", \"content\": \"LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. The simplest way to create a tool-calling agent in LangGraph is to use create_react_agent: # Define the tools for the agent to use # Define the tools for the agent to use # This means that after `tools` is called, `agent` node is called next. workflow.add_edge(\\\\\"tools\\\\\", \\'agent\\') Normal edge: after the tools are invoked, the graph should always return to the agent to decide what to do next LangGraph adds the input message to the internal state, then passes the state to the entrypoint node, \\\\\"agent\\\\\". langgraph-0.2.70-py3-none-any.whl (149.7 kB view details)Uploaded Feb 6, 2025 Python 3\"}]', name='tavily_search_results_json', id='c10ffb13-7a2f-43a4-8ef6-0f25578bcb47', tool_call_id='call_EO7veL92xLNN8oENnAoL5RNj', artifact={'query': 'LangGraph release date', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://github.com/langchain-ai/langgraph/releases', 'title': 'Releases · langchain-ai/langgraph - GitHub', 'content': \"Releases · langchain-ai/langgraph · GitHub Search code, repositories, users, issues, pull requests... Releases: langchain-ai/langgraph Releases · langchain-ai/langgraph langgraph: release 0.2.70 (#3341) langgraph: add agent name to AI messages in create_react_agent (#3340) fix(langgraph): Dedupe input (right-side) messages in add_messages (#3338) Merge branch 'jacob/dedupe' of github.com:langchain-ai/langgraph into jacob/dedupe langgraph: release 0.2.69 (#3256) docs: update README to include built w/ langgraph (#3254) langgraph: add get_stream_writer() (#3251) langgraph: release 0.2.68 (#3224) langgraph: actually fix flaky test (#3219) langgraph: use 'prompt' param for model input preprocessing in create_react_agent (#3173) langgraph: fix flaky test (#3218) langgraph: add names for tasks (#3202) langgraph: update docstrings/api ref for functional api (#3176) langgraph: add support for BaseModel updates to Command (#2747) langgraph: allow async state modifier in create_react_agent (#3161)\", 'score': 0.72418857, 'raw_content': None}, {'url': 'https://pypi.org/project/langgraph/', 'title': 'langgraph · PyPI', 'content': 'LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. The simplest way to create a tool-calling agent in LangGraph is to use create_react_agent: # Define the tools for the agent to use # Define the tools for the agent to use # This means that after `tools` is called, `agent` node is called next. workflow.add_edge(\"tools\", \\'agent\\') Normal edge: after the tools are invoked, the graph should always return to the agent to decide what to do next LangGraph adds the input message to the internal state, then passes the state to the entrypoint node, \"agent\". langgraph-0.2.70-py3-none-any.whl (149.7 kB view details)Uploaded Feb 6, 2025 Python 3', 'score': 0.68571854, 'raw_content': None}], 'response_time': 1.37}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_PErDtZj1ubVAMokPKxzl2hjy', 'function': {'arguments': '{\"name\":\"LangGraph\",\"birthday\":\"February 6, 2025\"}', 'name': 'human_assistance'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 648, 'total_tokens': 676, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d36e03f9-2782-482c-b359-1c0be09028c5-0', tool_calls=[{'name': 'human_assistance', 'args': {'name': 'LangGraph', 'birthday': 'February 6, 2025'}, 'id': 'call_PErDtZj1ubVAMokPKxzl2hjy', 'type': 'tool_call'}], usage_metadata={'input_tokens': 648, 'output_tokens': 28, 'total_tokens': 676, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"Made a correction: {'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}\", name='human_assistance', id='fe6b8499-9f68-450d-9a45-4737b5d8a9d0', tool_call_id='call_PErDtZj1ubVAMokPKxzl2hjy'), AIMessage(content='LangGraph was released on January 17, 2024.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 707, 'total_tokens': 722, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-cf28e16a-aa8b-41f1-81c8-57df1b3b3c73-0', usage_metadata={'input_tokens': 707, 'output_tokens': 15, 'total_tokens': 722, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], 'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1eff9968-7624-6428-8005-7f92157c76e0'}}, metadata={'source': 'loop', 'writes': {'chatbot': {'messages': [AIMessage(content='LangGraph was released on January 17, 2024.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 707, 'total_tokens': 722, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-cf28e16a-aa8b-41f1-81c8-57df1b3b3c73-0', usage_metadata={'input_tokens': 707, 'output_tokens': 15, 'total_tokens': 722, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}, 'thread_id': '1', 'step': 5, 'parents': {}}, created_at='2025-03-05T07:50:38.354922+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1eff9968-67a9-6ff6-8004-68edca3c4f03'}}, tasks=())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that these fields are now reflected in the state\n",
    "snapshot = graph.get_state(config)\n",
    "snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1eff9974-c2ec-6236-8006-97a6402d04c4'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually updating state\n",
    "graph.update_state(config, {\"name\": \"LangGraph (library)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangGraph (library)', 'birthday': 'Jan 17, 2024'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
